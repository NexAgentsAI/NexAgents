{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Saving State \n",
    "\n",
    "So far, we have discussed how to build components in a multi-agent application - agents, teams, termination conditions. In many cases, it is useful to save the state of these components to disk and load them back later. This is particularly useful in a web application where stateless endpoints respond to requests and need to load the state of the application from persistent storage.\n",
    "\n",
    "In this notebook, we will discuss how to save and load the state of agents, teams, and termination conditions. \n",
    " \n",
    "\n",
    "# Saving and Loading Agents\n",
    "\n",
    "We can get the state of an agent by calling `save_state` method on the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep blue whispers flow,  \n",
      "Ancient depths of Tanganyika,  \n",
      "Nature's mirror glows.  \n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.task import Console, MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models import OpenAIChatCompletionClient\n",
    "\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = await assistant_agent.run(task=\"Write a 3 line poem on lake tangayika\")\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantAgentState(state_type='AssistantAgent', version='1.0.0', model_context=[UserMessage(content='Write a 3 line poem on lake tangayika', source='user'), AssistantMessage(content=\"Deep blue whispers flow,  \\nAncient depths of Tanganyika,  \\nNature's mirror glows.  \", source='assistant_agent')])\n"
     ]
    }
   ],
   "source": [
    "agent_state = await assistant_agent.save_state()\n",
    "print(agent_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last line of the poem I wrote was:   \n",
      "\"Nature's mirror glows.\"\n"
     ]
    }
   ],
   "source": [
    "new_assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    ")\n",
    "await new_assistant_agent.load_state(agent_state)\n",
    "result = await new_assistant_agent.run(task=\"What was the last line of the previous poem you wrote\")\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Agent state mainly consists of the model_context as the agent's state. If your agent has additional state you would like to save and load, consider overriding the `save_state` and `load_state` methods.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Teams \n",
    "\n",
    "We can get the state of a team by calling `save_state` method on the team and load it back by calling `load_state` method on the team. \n",
    "\n",
    "A team typically is composed of agents and some termination conditions. When we call `save_state` on a team, it saves the state of all the agents in the team and the termination conditions.  \n",
    "\n",
    "We will begin by creating a simple RoundRobinGroupChat team with a single agent and ask it to write a poem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a beautiful poem 3-line about lake tangayika\n",
      "---------- assistant_agent ----------\n",
      "Cradled 'tween the hills, Lake Tanganyika's grace,  \n",
      "Mirrors twilight's blush, whispers secrets of time,  \n",
      "Depths cradle ancient dreams beneath moonlit lace.  \n",
      "[Prompt tokens: 29, Completion tokens: 39]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Maximum number of messages 2 reached, current message count: 2\n",
      "Total prompt tokens: 29\n",
      "Total completion tokens: 39\n",
      "Duration: 0.71 seconds\n"
     ]
    }
   ],
   "source": [
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    ")\n",
    "# Define a team\n",
    "agent_team = RoundRobinGroupChat([assistant_agent], termination_condition=MaxMessageTermination(max_messages=2))\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=\"Write a beautiful poem 3-line about lake tangayika\")\n",
    "await Console(stream)\n",
    "team_state = await agent_team.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we reset the team (simulating instantiation of the team),  and ask the question `What was the last line of the poem you wrote?`, we see that the team is unable to accomplish this as there is no reference to the previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What was the last line of the poem you wrote?\n",
      "---------- assistant_agent ----------\n",
      "I’m sorry, but I don’t have the ability to recall past interactions or previously written content. If you’d like, I can generate a new poem for you.\n",
      "[Prompt tokens: 28, Completion tokens: 34]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Maximum number of messages 2 reached, current message count: 2\n",
      "Total prompt tokens: 28\n",
      "Total completion tokens: 34\n",
      "Duration: 0.60 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What was the last line of the poem you wrote?'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=34), content='I’m sorry, but I don’t have the ability to recall past interactions or previously written content. If you’d like, I can generate a new poem for you.')], stop_reason='Maximum number of messages 2 reached, current message count: 2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent_team.reset()\n",
    "stream = agent_team.run_stream(task=\"What was the last line of the poem you wrote?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the state of the team and ask the same question. We see that the team is able to accurately return the last line of the poem it wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What was the last line of the poem you wrote?\n",
      "---------- assistant_agent ----------\n",
      "The last line of the poem is: \"Depths cradle ancient dreams beneath moonlit lace.\"\n",
      "[Prompt tokens: 91, Completion tokens: 19]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Maximum number of messages 2 reached, current message count: 2\n",
      "Total prompt tokens: 91\n",
      "Total completion tokens: 19\n",
      "Duration: 0.43 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What was the last line of the poem you wrote?'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=91, completion_tokens=19), content='The last line of the poem is: \"Depths cradle ancient dreams beneath moonlit lace.\"')], stop_reason='Maximum number of messages 2 reached, current message count: 2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent_team.load_state(team_state)\n",
    "stream = agent_team.run_stream(task=\"What was the last line of the poem you wrote?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Termination Conditions\n",
    "\n",
    "We can get the state of a termination condition by calling `save_state` method on the termination condition and load it back by calling `load_state` method on the termination condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrTerminationState(state_type='OrTerminationState', version='1.0.0', terminated=False, condition_states=[TextMentionTerminationState(state_type='TextMentionTerminationState', version='1.0.0', terminated=False, text='stop'), MaxMessageTerminationState(state_type='MaxMessageTerminationState', version='1.0.0', terminated=False, message_count=0, max_messages=2)])\n"
     ]
    }
   ],
   "source": [
    "max_termination = MaxMessageTermination(max_messages=2)\n",
    "text_termination = TextMentionTermination(text=\"stop\")\n",
    "termination = text_termination | max_termination\n",
    "termination_state = await termination.save_state()\n",
    "print(termination_state)\n",
    "await termination.load_state(termination_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
